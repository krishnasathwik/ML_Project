{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed1624ee-a844-4e84-9792-bd42c72f7c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data null values:\n",
      " LoanID            0\n",
      "Age               0\n",
      "Income            0\n",
      "LoanAmount        0\n",
      "CreditScore       0\n",
      "MonthsEmployed    0\n",
      "NumCreditLines    0\n",
      "InterestRate      0\n",
      "LoanTerm          0\n",
      "DTIRatio          0\n",
      "Education         0\n",
      "EmploymentType    0\n",
      "MaritalStatus     0\n",
      "HasMortgage       0\n",
      "HasDependents     0\n",
      "LoanPurpose       0\n",
      "HasCoSigner       0\n",
      "Default           0\n",
      "dtype: int64\n",
      "Test data null values:\n",
      " LoanID            0\n",
      "Age               0\n",
      "Income            0\n",
      "LoanAmount        0\n",
      "CreditScore       0\n",
      "MonthsEmployed    0\n",
      "NumCreditLines    0\n",
      "InterestRate      0\n",
      "LoanTerm          0\n",
      "DTIRatio          0\n",
      "Education         0\n",
      "EmploymentType    0\n",
      "MaritalStatus     0\n",
      "HasMortgage       0\n",
      "HasDependents     0\n",
      "LoanPurpose       0\n",
      "HasCoSigner       0\n",
      "dtype: int64\n",
      "Validation accuracy for Naive Bayes: 0.8839\n",
      "Final submission file 'sample_submission_nb.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Setting random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the train and test datasets\n",
    "train = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Check for null values\n",
    "print(\"Train data null values:\\n\", train.isnull().sum())\n",
    "print(\"Test data null values:\\n\", test_data.isnull().sum())\n",
    "\n",
    "# Remove duplicates from train data if any\n",
    "train = train.drop_duplicates()\n",
    "\n",
    "# Store LoanID from test data for the final submission\n",
    "test_loan_ids = test_data['LoanID']\n",
    "\n",
    "# Define the OutlierRemoval class\n",
    "class OutlierRemoval:\n",
    "    def __init__(self, col):\n",
    "        q1 = col.quantile(0.25)\n",
    "        q3 = col.quantile(0.75)\n",
    "        inter_quartile_range = q3 - q1\n",
    "        self.upper_whisker = q3 + inter_quartile_range * 1.5\n",
    "        self.lower_whisker = q1 - inter_quartile_range * 1.5\n",
    "\n",
    "    def remove(self, row):\n",
    "        if self.lower_whisker <= row <= self.upper_whisker:\n",
    "            return row\n",
    "        elif row < self.lower_whisker:\n",
    "            return self.lower_whisker\n",
    "        else:\n",
    "            return self.upper_whisker\n",
    "\n",
    "# Identify numerical columns\n",
    "numerical_columns = ['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed', \n",
    "                     'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio']\n",
    "\n",
    "# Apply outlier removal on numerical columns in train and test data\n",
    "for column in numerical_columns:\n",
    "    remover = OutlierRemoval(train[column])\n",
    "    train[column] = train[column].apply(remover.remove)\n",
    "    \n",
    "    test_remover = OutlierRemoval(test_data[column])\n",
    "    test_data[column] = test_data[column].apply(test_remover.remove)\n",
    "\n",
    "# Define mappings for categorical columns\n",
    "mappings = {\n",
    "    'MaritalStatus': {'Married': 0, 'Single': 1, 'Divorced': 2},\n",
    "    'Education': {'High School': 0, \"Bachelor's\": 1, 'Master\\'s': 2},\n",
    "    'EmploymentType': {'Full-time': 0, 'Part-time': 1, 'Self-employed': 2, 'Unemployed': 3},\n",
    "    'HasMortgage': {'Yes': 1, 'No': 0},\n",
    "    'HasDependents': {'Yes': 1, 'No': 0},\n",
    "    'LoanPurpose': {'Home': 0, 'Auto': 1, 'Education': 2, 'Business': 3, 'Other': 4},\n",
    "    'HasCoSigner': {'Yes': 1, 'No': 0}\n",
    "}\n",
    "\n",
    "# Apply mappings to train and test data\n",
    "for col, mapping in mappings.items():\n",
    "    train[col] = train[col].map(mapping)\n",
    "    test_data[col] = test_data[col].map(mapping)\n",
    "\n",
    "# Feature engineering: Combine MaritalStatus and HasDependents into a new feature\n",
    "train['Marital_Dependents'] = train['MaritalStatus'] + train['HasDependents']\n",
    "test_data['Marital_Dependents'] = test_data['MaritalStatus'] + test_data['HasDependents']\n",
    "\n",
    "# Drop the LoanID column from train data (not needed for training)\n",
    "train = train.drop(columns=['LoanID'])\n",
    "test_data = test_data.drop(columns=['LoanID'])\n",
    "\n",
    "# Separate target variable\n",
    "X = train.drop(columns=['Default'])\n",
    "y = train['Default']\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize numerical columns\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
    "X_val[numerical_columns] = scaler.transform(X_val[numerical_columns])\n",
    "test_data[numerical_columns] = scaler.transform(test_data[numerical_columns])\n",
    "\n",
    "# Apply KNN imputation\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "X_train = pd.DataFrame(knn_imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "X_val = pd.DataFrame(knn_imputer.transform(X_val), columns=X_val.columns)\n",
    "test_data = pd.DataFrame(knn_imputer.transform(test_data), columns=test_data.columns)\n",
    "\n",
    "# Train and evaluate Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_nb = nb_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the Naive Bayes model\n",
    "accuracy_nb = accuracy_score(y_val, y_pred_nb)\n",
    "print(f\"Validation accuracy for Naive Bayes: {accuracy_nb:.4f}\")\n",
    "\n",
    "# Make predictions on the test set using Naive Bayes\n",
    "test_predictions_nb = nb_classifier.predict(test_data)\n",
    "\n",
    "# Prepare final submission file for Naive Bayes\n",
    "sample_submission_nb = pd.DataFrame({'LoanID': test_loan_ids, 'Default': test_predictions_nb})\n",
    "sample_submission_nb.to_csv('sample_submission_nb.csv', index=False)\n",
    "\n",
    "print(\"Final submission file 'sample_submission_nb.csv' created successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
